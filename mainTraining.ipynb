{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mainTraining.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1H3aSv3aperO_46rtmWKh1PJbLkXMq0pj","authorship_tag":"ABX9TyMjT2y3pAn/dUgOCeW8Txe0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"82k1teo0yNar","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597210104096,"user_tz":-480,"elapsed":861,"user":{"displayName":"sidhant Naveria","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOMM9zhLQbtCmJN3V1WawpoqtGTwRx4e-8LbT0=s64","userId":"08376082764677086360"}}},"source":["import numpy as np\n","import os\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","from torch.utils.data.sampler import SubsetRandomSampler\n","from torch.utils.data import Subset\n","from sklearn.model_selection import train_test_split\n","\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","from Autoencoder import ConvAutoencoder as convenc \n","from DataGenerator import DatasetGenerator\n","from sklearn.cluster import KMeans\n","from sklearn.neighbors import NearestNeighbors\n","import pickle\n","from torch.autograd import Variable"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"bq_5MC1D7wPw","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597138095479,"user_tz":-480,"elapsed":1118,"user":{"displayName":"sidhant Naveria","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOMM9zhLQbtCmJN3V1WawpoqtGTwRx4e-8LbT0=s64","userId":"08376082764677086360"}}},"source":["\n","path=\"/content/drive/My Drive/dataset/\"\n","model_file=\"/content/drive/My Drive/final.pkl\"\n","\n","transform = transforms.Compose([\n","    transforms.RandomRotation(degrees=15),\n","    transforms.Resize((224,224)),\n","    transforms.ToTensor()\n","    \n","])\n","\n","train_dataset = DatasetGenerator(pathImageDirectory=path, transform=transform)\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=1, \n","                                           shuffle=False, num_workers=8)\n","\n"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"90_IWGrQ1nqb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597069424160,"user_tz":-480,"elapsed":14721070,"user":{"displayName":"sidhant Naveria","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOMM9zhLQbtCmJN3V1WawpoqtGTwRx4e-8LbT0=s64","userId":"08376082764677086360"}},"outputId":"2e72e5e9-12e0-46e0-ca6f-afc57026fb59"},"source":["# Training the Autoencoder\n","\n","model=convenc()\n","# specify loss function\n","criterion = nn.BCELoss()\n","\n","# specify loss function\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","# number of epochs to train the model\n","n_epochs = 100\n","\n","for epoch in range(1, n_epochs+1):\n","    # monitor training loss\n","    train_loss = 0.0\n","    \n","    ###################\n","    # train the model #\n","    ###################\n","    for data in train_loader:\n","        # _ stands in for filename, here\n","        # no need to flatten images\n","        images, _ = data\n","        # clear the gradients of all optimized variables\n","        optimizer.zero_grad()\n","        # forward pass: compute predicted outputs by passing inputs to the model\n","        outputs = model(images)\n","        # calculate the loss\n","        loss = criterion(outputs, images)\n","        # backward pass: compute gradient of the loss with respect to model parameters\n","        loss.backward()\n","        # perform a single optimization step (parameter update)\n","        optimizer.step()\n","        # update running training loss\n","        train_loss += loss.item()*images.size(0)\n","            \n","    # print avg training statistics \n","    train_loss = train_loss/len(train_loader)\n","    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n","        epoch, \n","        train_loss\n","        ))\n","torch.save(model.state_dict(), model_file) #saving the model"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n","  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch: 1 \tTraining Loss: 3.632466\n","Epoch: 2 \tTraining Loss: 3.430237\n","Epoch: 3 \tTraining Loss: 3.421157\n","Epoch: 4 \tTraining Loss: 3.410888\n","Epoch: 5 \tTraining Loss: 3.407243\n","Epoch: 6 \tTraining Loss: 3.404159\n","Epoch: 7 \tTraining Loss: 3.405836\n","Epoch: 8 \tTraining Loss: 3.401446\n","Epoch: 9 \tTraining Loss: 3.398049\n","Epoch: 10 \tTraining Loss: 3.400801\n","Epoch: 11 \tTraining Loss: 3.395616\n","Epoch: 12 \tTraining Loss: 3.397542\n","Epoch: 13 \tTraining Loss: 3.398632\n","Epoch: 14 \tTraining Loss: 3.398113\n","Epoch: 15 \tTraining Loss: 3.394994\n","Epoch: 16 \tTraining Loss: 3.395583\n","Epoch: 17 \tTraining Loss: 3.397152\n","Epoch: 18 \tTraining Loss: 3.396963\n","Epoch: 19 \tTraining Loss: 3.395959\n","Epoch: 20 \tTraining Loss: 3.396124\n","Epoch: 21 \tTraining Loss: 3.394416\n","Epoch: 22 \tTraining Loss: 3.394082\n","Epoch: 23 \tTraining Loss: 3.394741\n","Epoch: 24 \tTraining Loss: 3.395676\n","Epoch: 25 \tTraining Loss: 3.394509\n","Epoch: 26 \tTraining Loss: 3.389257\n","Epoch: 27 \tTraining Loss: 3.393067\n","Epoch: 28 \tTraining Loss: 3.391237\n","Epoch: 29 \tTraining Loss: 3.392227\n","Epoch: 30 \tTraining Loss: 3.393535\n","Epoch: 31 \tTraining Loss: 3.392808\n","Epoch: 32 \tTraining Loss: 3.392684\n","Epoch: 33 \tTraining Loss: 3.391769\n","Epoch: 34 \tTraining Loss: 3.390751\n","Epoch: 35 \tTraining Loss: 3.392956\n","Epoch: 36 \tTraining Loss: 3.392025\n","Epoch: 37 \tTraining Loss: 3.391148\n","Epoch: 38 \tTraining Loss: 3.391311\n","Epoch: 39 \tTraining Loss: 3.390749\n","Epoch: 40 \tTraining Loss: 3.390843\n","Epoch: 41 \tTraining Loss: 3.393222\n","Epoch: 42 \tTraining Loss: 3.392657\n","Epoch: 43 \tTraining Loss: 3.390661\n","Epoch: 44 \tTraining Loss: 3.391881\n","Epoch: 45 \tTraining Loss: 3.391036\n","Epoch: 46 \tTraining Loss: 3.389720\n","Epoch: 47 \tTraining Loss: 3.391982\n","Epoch: 48 \tTraining Loss: 3.389774\n","Epoch: 49 \tTraining Loss: 3.393299\n","Epoch: 50 \tTraining Loss: 3.391243\n","Epoch: 51 \tTraining Loss: 3.389012\n","Epoch: 52 \tTraining Loss: 3.388274\n","Epoch: 53 \tTraining Loss: 3.389366\n","Epoch: 54 \tTraining Loss: 3.390943\n","Epoch: 55 \tTraining Loss: 3.388285\n","Epoch: 56 \tTraining Loss: 3.379670\n","Epoch: 57 \tTraining Loss: 3.365720\n","Epoch: 58 \tTraining Loss: 3.362426\n","Epoch: 59 \tTraining Loss: 3.364260\n","Epoch: 60 \tTraining Loss: 3.360198\n","Epoch: 61 \tTraining Loss: 3.363155\n","Epoch: 62 \tTraining Loss: 3.358876\n","Epoch: 63 \tTraining Loss: 3.361768\n","Epoch: 64 \tTraining Loss: 3.360010\n","Epoch: 65 \tTraining Loss: 3.358674\n","Epoch: 66 \tTraining Loss: 3.360921\n","Epoch: 67 \tTraining Loss: 3.359748\n","Epoch: 68 \tTraining Loss: 3.359810\n","Epoch: 69 \tTraining Loss: 3.358564\n","Epoch: 70 \tTraining Loss: 3.358815\n","Epoch: 71 \tTraining Loss: 3.358888\n","Epoch: 72 \tTraining Loss: 3.358994\n","Epoch: 73 \tTraining Loss: 3.356054\n","Epoch: 74 \tTraining Loss: 3.355218\n","Epoch: 75 \tTraining Loss: 3.360656\n","Epoch: 76 \tTraining Loss: 3.356143\n","Epoch: 77 \tTraining Loss: 3.359254\n","Epoch: 78 \tTraining Loss: 3.358613\n","Epoch: 79 \tTraining Loss: 3.358077\n","Epoch: 80 \tTraining Loss: 3.359532\n","Epoch: 81 \tTraining Loss: 3.358627\n","Epoch: 82 \tTraining Loss: 3.356648\n","Epoch: 83 \tTraining Loss: 3.358116\n","Epoch: 84 \tTraining Loss: 3.358485\n","Epoch: 85 \tTraining Loss: 3.355444\n","Epoch: 86 \tTraining Loss: 3.356974\n","Epoch: 87 \tTraining Loss: 3.356688\n","Epoch: 88 \tTraining Loss: 3.355464\n","Epoch: 89 \tTraining Loss: 3.356259\n","Epoch: 90 \tTraining Loss: 3.356239\n","Epoch: 91 \tTraining Loss: 3.357146\n","Epoch: 92 \tTraining Loss: 3.357660\n","Epoch: 93 \tTraining Loss: 3.357880\n","Epoch: 94 \tTraining Loss: 3.356993\n","Epoch: 95 \tTraining Loss: 3.358506\n","Epoch: 96 \tTraining Loss: 3.354263\n","Epoch: 97 \tTraining Loss: 3.357925\n","Epoch: 98 \tTraining Loss: 3.355728\n","Epoch: 99 \tTraining Loss: 3.355431\n","Epoch: 100 \tTraining Loss: 3.359610\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1xzfTzggypZj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1597138216925,"user_tz":-480,"elapsed":100465,"user":{"displayName":"sidhant Naveria","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOMM9zhLQbtCmJN3V1WawpoqtGTwRx4e-8LbT0=s64","userId":"08376082764677086360"}},"outputId":"c9212b03-5bd3-493b-becd-7e081473f333"},"source":["### creating input for KNN model\n","\n","class Identity(nn.Module): ##this class is used to get encoder output out of the autoencoder model by converting decoder layer to identity \n","    def __init__(self):\n","        super(Identity, self).__init__()\n","        \n","    def forward(self, x):\n","        return x\n","\n","model=convenc().cuda()\n","\n","\n","model.load_state_dict(torch.load(model_file))\n","\n","model.t_conv1=Identity()\n","model.t_conv2=Identity()\n","model.t_conv3=Identity()\n","\n","\n","train_flatten=np.empty((0,3136)) #3136 after flattening the output of model product of C,h,w is 3136\n","print(train_flatten.shape)\n","i=0\n","filenames=[]\n","for files,filename in train_loader:\n","\n","  images=Variable(files.cuda())\n","  output = model(images)\n","  \n","  temp=torch.flatten(output) \n","  \n","  temp=temp.to('cpu').detach().numpy()\n","  train_flatten=np.append(train_flatten,np.array([temp]),axis=0)\n","  filenames.append(filename)\n","  \n","\n","print(train_flatten.shape)  \n","print(len(filenames))\n","\n","'''\n","Uncomment below to save the filenames array as the index of this array will be used to match the \n","index from KNN to retrieve image file name\n","'''\n","\n","# from numpy import save\n","# arr_filename=np.array(filenames)\n","# save('/content/drive/My Drive/filename.npy',arr_filename)\n"],"execution_count":34,"outputs":[{"output_type":"stream","text":["(0, 3136)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n","  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["(4738, 3136)\n","4738\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AoNTgQ0nxqed","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1597138265248,"user_tz":-480,"elapsed":1370,"user":{"displayName":"sidhant Naveria","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjOMM9zhLQbtCmJN3V1WawpoqtGTwRx4e-8LbT0=s64","userId":"08376082764677086360"}},"outputId":"f329e4ba-2d63-40d6-953c-4f0637215cee"},"source":["# passing encoded images to KNN\n","\n","knn = NearestNeighbors(n_neighbors=5, metric=\"cosine\")\n","knn.fit(train_flatten)\n","\n","# test KNN model\n","\n","for i, emb_flatten in enumerate(train_flatten):\n","    _, indices = knn.kneighbors([emb_flatten]) # find k nearest train neighbours\n","    \n","    print(indices)\n","\n","### Uncomment below to save the KNN model\n","\n","# with open(''/content/drive/My Drive/KNN.pkl'', 'wb') as f:\n","#    pickle.dump(knn, f)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Performing image retrieval on test images...\n","[[   0   12 4166 4570 3262]]\n"],"name":"stdout"}]}]}